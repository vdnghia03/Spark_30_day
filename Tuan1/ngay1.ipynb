{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngày 1: Giới thiệu về Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Big Data** là gì ?\n",
    "**Big Data** là thuật ngữ dùng để mô tả khối lượng dữ liệu rất lớn và phức tạp, thường được tạo ra với tốc độ nhanh từ nhiều nguồn khác nhau. Do kích thước và độ phức tạp của nó, Big Data không thể được quản lý, xử lý hoặc phân tích bằng các công cụ và kỹ thuật truyền thống. Thay vào đó, cần sử dụng các công nghệ và công cụ đặc biệt để xử lý và khai thác giá trị từ nó.\n",
    "\n",
    "Đặc điểm của Big Data (3V + 2V):\n",
    "- Volume(Khối lượng)\n",
    "- Velocity(Tốc độ)\n",
    "- Variety(Đa dạng)\n",
    "- Veracity(Độ chính xác)\n",
    "- Value(Giá trị)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spark là gì, ưu điểm của Spark\n",
    "\n",
    "- Spark: Là một tool xử lí và phân tích dữ liệu lớn\n",
    "- Ưu điểm: \n",
    "    - Advanced Analytics: Spark không chỉ hỗ trợ \"Map\" và \"Reduce \", nó còn hỗ trợ Spark truy vấn SQL, Streaming data, Machine learning (ML) và các thuật toán xử lý đồ thị đóng vai trò như một bộ công cụ phân tích dữ liệu cực kì mạnh mẽ.\n",
    "    - Speed: Spark giúp chạy một ứng dụng với tốc độ rất nhanh. So với Hadoop cluster, Spark Application nến chạy trên bộ nhớ nhanh hơn tới 100 lần và nhanh hơn 10 lần khi chạy trên đĩa. Điều này có được nhờ giảm số lượng các hoạt động đọc / ghi vào ổ đĩa.\n",
    "    - Supports multiple languages: Spark cung cấp built-in APIs phổ biến từ Java, Scala đến Python, R. Do đó, có thể code Spark applications với nhiều lựa chọn về ngôn ngữ lập trình. Bên cạnh đó Spark còn cung cấp rất nhiều high-level operators cho việc truy vấn dữ liệu..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Kiến trúc tổng quan\n",
    "\n",
    "- Tổng quát\n",
    "![architech](image_1/spark_architech.png)\n",
    "\n",
    "- Chi tiết\n",
    "![architech](image_1/architech_complex.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Các thành phần"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apache Spark** có **2 layer**:\n",
    "- Layer 1: Spark Core API (Chủ yếu sử lí RDD)\n",
    "- Layer 2: High level API\n",
    "\n",
    "![Component](image_1/layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. So sánh với Hadoop MapReduce\n",
    "\n",
    "Spark được sinh ra để cải thiện hiệu xuất của MapReduce của Hadoop\n",
    "\n",
    "Hiệu suất: Spark nhanh hơn map reduce từ 10 đến 100 lần\n",
    "\n",
    "\n",
    "- Mapreduce\\\n",
    "![mapreduce](image_1/mapreduce.png)\n",
    "\n",
    "- Spark\\\n",
    "![spark](image_1/spark.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tâp ngày 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài 1**:  Cài đặt Spark trên máy cục bộ và chạy ứng dụng \"Word Count\" mẫu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/21 23:21:32 WARN Utils: Your hostname, ubunchuu-Test resolves to a loopback address: 127.0.1.1; using 10.0.232.111 instead (on interface wlo1)\n",
      "24/10/21 23:21:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/21 23:21:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/21 23:21:45 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.textFile(\"material_1/wordcount.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello my name is Nghia',\n",
       " 'I am ten years old',\n",
       " 'I live in Ho Chin Minh City now',\n",
       " 'I study at University of Science, in Ho Chi Minh city, Viet Nam',\n",
       " 'Vinh is my friend. He also live in Ho Chi Minh']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd1.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Nghia',\n",
       " 'I',\n",
       " 'am',\n",
       " 'ten',\n",
       " 'years',\n",
       " 'old',\n",
       " 'I',\n",
       " 'live',\n",
       " 'in',\n",
       " 'Ho',\n",
       " 'Chin',\n",
       " 'Minh',\n",
       " 'City',\n",
       " 'now',\n",
       " 'I',\n",
       " 'study',\n",
       " 'at',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Science,',\n",
       " 'in',\n",
       " 'Ho',\n",
       " 'Chi',\n",
       " 'Minh',\n",
       " 'city,',\n",
       " 'Viet',\n",
       " 'Nam',\n",
       " 'Vinh',\n",
       " 'is',\n",
       " 'my',\n",
       " 'friend.',\n",
       " 'He',\n",
       " 'also',\n",
       " 'live',\n",
       " 'in',\n",
       " 'Ho',\n",
       " 'Chi',\n",
       " 'Minh']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd2.map(lambda word :(word, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 1),\n",
       " ('my', 1),\n",
       " ('name', 1),\n",
       " ('is', 1),\n",
       " ('Nghia', 1),\n",
       " ('I', 1),\n",
       " ('am', 1),\n",
       " ('ten', 1),\n",
       " ('years', 1),\n",
       " ('old', 1),\n",
       " ('I', 1),\n",
       " ('live', 1),\n",
       " ('in', 1),\n",
       " ('Ho', 1),\n",
       " ('Chin', 1),\n",
       " ('Minh', 1),\n",
       " ('City', 1),\n",
       " ('now', 1),\n",
       " ('I', 1),\n",
       " ('study', 1),\n",
       " ('at', 1),\n",
       " ('University', 1),\n",
       " ('of', 1),\n",
       " ('Science,', 1),\n",
       " ('in', 1),\n",
       " ('Ho', 1),\n",
       " ('Chi', 1),\n",
       " ('Minh', 1),\n",
       " ('city,', 1),\n",
       " ('Viet', 1),\n",
       " ('Nam', 1),\n",
       " ('Vinh', 1),\n",
       " ('is', 1),\n",
       " ('my', 1),\n",
       " ('friend.', 1),\n",
       " ('He', 1),\n",
       " ('also', 1),\n",
       " ('live', 1),\n",
       " ('in', 1),\n",
       " ('Ho', 1),\n",
       " ('Chi', 1),\n",
       " ('Minh', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4 = rdd3.reduceByKey(lambda x, y: x+y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Hello', 1),\n",
       " ('name', 1),\n",
       " ('is', 2),\n",
       " ('am', 1),\n",
       " ('ten', 1),\n",
       " ('years', 1),\n",
       " ('live', 2),\n",
       " ('in', 3),\n",
       " ('Chin', 1),\n",
       " ('now', 1),\n",
       " ('at', 1),\n",
       " ('University', 1),\n",
       " ('of', 1),\n",
       " ('Science,', 1),\n",
       " ('Chi', 2),\n",
       " ('Viet', 1),\n",
       " ('Nam', 1),\n",
       " ('friend.', 1),\n",
       " ('my', 2),\n",
       " ('Nghia', 1),\n",
       " ('I', 3),\n",
       " ('old', 1),\n",
       " ('Ho', 3),\n",
       " ('Minh', 3),\n",
       " ('City', 1),\n",
       " ('study', 1),\n",
       " ('city,', 1),\n",
       " ('Vinh', 1),\n",
       " ('He', 1),\n",
       " ('also', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
