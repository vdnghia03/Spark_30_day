{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngày 5: Shared Variable và Spark UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Shard Variable\n",
    "Spark theo mặc định không hỗ trợ thay đổi trạng thái biến được chia sẻ trên các Worker Node. Share variables giúp giải quyết một số giới hạn của kiến trúc này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Broadcast Variable**\n",
    "   \n",
    "*Khái niệm*: Broadcast variables dùng để chia sẻ một biến chỉ đọc đến tất cả worker node, nhằm giảm việc truyền dữ liệu lặp đi lặp lại.\n",
    "\n",
    "*Sử dụng:* \n",
    "- Broadcast một từ điển lớn hoặc dữ liệu tham khỏa để tất cả worker node có thể truy cập mà không phải tải lại từ đầu.\n",
    "- Lợi ích của Broadcast variables là giảm băng thông và cải thiện hiệu suất.\n",
    "\n",
    "*Cú pháp và ví dụ:*\n",
    "```python\n",
    "    broadcast_val = sc.broadcast(large_dict)\n",
    "    rdd.map(lambda x : some_function(x , broadcast_var.value))\n",
    "```\n",
    "\n",
    "![BroadCast](image_1/broadcast_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Accumulators:**\n",
    "\n",
    "*Khái niệm:* Accumulators là các biến có thể đếm hoặc tổng hợp dữ liệu trên các worker node, thường dùng để theo dõi số liệu hoặc lỗi mà không ảnh hưởng đến trạng thái ứng dụng.\n",
    "\n",
    "*Sử dụng:* Theo dõi số lượng bản ghi lỗi hoặc số liệu thống kê\n",
    "\n",
    "*Cú pháp và ví dụ:* \n",
    "\n",
    "```python\n",
    "    accumulator = sc.accumulator(0)\n",
    "    rdd.foreach( lambda x: accumulator.add(1) if x == 'error' else None)\n",
    "```\n",
    "\n",
    "![Accumulator](image_1/accumulator_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Spark UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ba thành phần chính của Spark UI: **JOB  -  STAGE - TASK**\n",
    "\n",
    "- Một JOB có nhiều STAGE\n",
    "- Một STAGE có nhiều TASK\n",
    "\n",
    "![Spark UI](image_1/SparkUI.png)\n",
    "\n",
    "<p style = \"color:green;\">Vậy JOB, STAGE, TASK được hình thành như thế nào ?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sự hình thành JOB\n",
    "\n",
    "Bản chất 1 JOB trong spark UI là 1 Actions khi ta thực hiện một Application trên RDD.\n",
    "\n",
    "1 JOB = 1 ACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sự hình thành của STAGE\n",
    "\n",
    "- Một JOB bao gồm nhiều Stage, đại diện cho các bước trong quá trình thực thi.\n",
    "- Ở đây ta lưu ý với hiện tượng Shuffle, Wide transformation có suffle còn narrow transformation thì không.\n",
    "- Một Job có nhiều Stage với:\n",
    "  - Số lượng Stage = Số lượng Wide Transformations + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sự hình thành TASK\n",
    "\n",
    "Số lượng **TASK** = Số lượng **PARTITION**\n",
    "\n",
    "_Vậy câu hỏi được đặt ra là, làm thế nào để biết số lượng PARTITION mà SPARK sử lí._\n",
    "\n",
    "Trước tiên phải hiểu về Task và Partition trong kiến trúc Cluster của Spark\n",
    "\n",
    "![executor](image_1/executor.png)\n",
    "\n",
    "Các **task** bên trong các **Executor** là các **Partition**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Vậy SPARK chia partition như thế nào ?_\n",
    "\n",
    "Về kiến thức, việc chia ra các **Executor và Partition** thuộc phạm vi **tối ưu** khi làm việc với Spark\n",
    "\n",
    "- Ở Executor: thường người ta chia ra trong 1 Executor sẽ có 5 Core CPU, mỗi Core CPU sẽ đảm nhiệm 1 task và thực hiện sử lí song song các task đó trong cùng 1 Executor\n",
    "\n",
    "- Ở Partiton(task):\n",
    "    - Mặc định: Spark có cơ chế tự động phân tách Partition và tự động tối ưu số lượng Partion\n",
    "        ```python\n",
    "            from pyspark.sql import SparkSesstion\n",
    "            spark = SparkSession.\\\n",
    "                builder.\\\n",
    "                master(\"local[4]\").\\\n",
    "                appName(\"nb_partition\").\\\n",
    "                getOrCreate()   \n",
    "\n",
    "            orders_schema = \"order_id long, order_date date, customer_id long, order_status string\"\n",
    "\n",
    "            orders_df = spark.read \\\n",
    "                .format(\"csv\") \\\n",
    "                .schema(orders_schema) \\\n",
    "                .load(\"C:/data/orders_1gb.csv\")\n",
    "\n",
    "            spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "            # Kết quả mặc định là 200 -> Tức là Mặc định khi load dữ liệu vào Spark sẽ chia 200 partition\n",
    "\n",
    "            spark.conf.get(\"spark.sql.adaptive.enabled\")\n",
    "            # Tuy nhiên, khi xem spark UI sẽ thấy số lượng Partiton nhỏ hơn rất nhiều\n",
    "            # Nguyên nhân là Spark có cơ chế tối ưu số lượng Partion\n",
    "\n",
    "            spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")\n",
    "            # Tắt tối ưu sẽ thấy số lượng partion là 200 trong Spark UI\n",
    "\n",
    "        ```\n",
    "    - Tuy nhiên, là một Data Engineer, bạn không thể phụ thuộc hoàn toàn vào Spark, tùy dự án cụ thể mà \n",
    "bạn là người data engineer phải tính ra số lượng Partion phù hợp, số executor phù hợp với dự án.\n",
    "\n",
    "    - Theo kinh nghiệm, ta có thể tính số lượng Partition theo công thức sau:\n",
    "        - Nếu 1 File : SL Partition = MAX[ (File_Size)/128MB ,  Số lượng Core]\n",
    "        - Nếu nhiều File: SL Partition = MAX [Số lượng File/(128/file_size_average  +  4MB)  ,  Số lượng Core]\n",
    "\n",
    "![SL Partion](image_1/partition_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
