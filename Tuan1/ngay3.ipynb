{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngày 3: Transformations & Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation & action là hai operation trên RDD. Ta cùng tìm hiểu thôi nào :))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lazy Evaluation (lazy là lười biếng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Việc xử lý dữ liệu, nhìn rộng ra, chính là việc biến đổi từ tập dữ liệu này sang tập dữ liêu khác, hay với Spark, là biến đổi từ RDD này sang RDD khác.\n",
    "\n",
    "**Khái niệm**: Spark không thực hiện tính toán ngay lập tức khi bạn gọi các transformations. Thay vào đó, Spark xây dựng một \"DAG\" (Directed Acyclic Graph) và chỉ thực hiện tính toán khi có một action được gọi.\n",
    "\n",
    "- Lợi ích: Tối ưu hóa các bước tính toán\n",
    "- Giảm thiểu số lượng bước thừa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Ví dụ: Ở đây ta có 1 tập dữ liệu với 1 tỉ record chứa dữ liệu về các nước... Ta sẽ thực hiện các\n",
    "transformation trên tập này như hình bên dưới.\n",
    "\n",
    "![image](image_1/lazy.png)\n",
    "\n",
    "**Giải thích**: Ở hình trên ta đang thực hiện 3 transformation là:\n",
    "- RDD1: Load to memory\n",
    "- RDD2: group by()\n",
    "- RDD3: Filter from RDD2\n",
    "- Action: show()\n",
    "\n",
    "<p style = \"color: green;\">Vậy Spark lazy như thế nào ? </p>\n",
    "\n",
    "Ở đây ta có thể thấy mặc dù đã tạo ra 3 RDD nhưng thực chất không có RDD nào được thực thi cả. Spark cứ\n",
    "đợi cho đến khi nào có một action được gọi thì spark mới bắt đầu thực hiện phân tích các transfomation và\n",
    "đưa ra strategy tối ưu nhất.\n",
    "\n",
    "--> Chính việc đợi và đợi cho đến khi có một action được gọi chính là cơ chế LAZY\n",
    "\n",
    "<p style = \"color: green;\">Vậy tại sao Spark lại phải lazy ? </p>\n",
    "\n",
    "![whylazy](image_1/notlazy.png)\n",
    "\n",
    "\n",
    "**Giải thích:** Bạn so sánh khi lazy và không lazy xem. \n",
    "- Nếu không lazy thì cứ làm việc tuần tự như thế,\n",
    "nó sẽ load 1 tỷ recore lên memory, tốn rất nhiều bộ nhớ.\n",
    "- Còn lazy, nó làm biếng nhưng thông minh hơn, nó xem xét thấy bước\n",
    "filter làm trước thì dữ liệu load lên memory chỉ 5 record,\n",
    "tiết khiệm rất nhiều dung lượng bộ nhớ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tóm lại:** Việc lazy là để cho spark có khả năng tính toán, lập kế hoạch và đưa ra được cái plan\n",
    "tối ưu nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Narrow vs. Wide transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations có hai loại và narrow và wide. Vậy hai loại này khác nhau như thế nào ?\n",
    "\n",
    "![shuffle](image_1/check.png)\n",
    "\n",
    "Sự khác biệt lớn nhất nằm ở việc có hay không có **shuffle**\n",
    "\n",
    "\n",
    "- Với narrow transformation: map, filter --> Không có shuffle\n",
    "- Với wide transformation: reduceByKey, sortByKey --> Có shuffle\n",
    "\n",
    "**Vậy shuffle ở đây là gì ?**\n",
    "\n",
    "Shuffle là hiện tượng xáo trộn dữ liệu giữa các node trong cluster để thu được kết quả đúng yêu cầu.\n",
    "\n",
    "![narrow and wide](image_1/compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Giải thích một chút về dữ liệu trong ảnh:\n",
    "  + Bối cảnh: Giả sử có một file dữ liệu lớn với 50k record. Yêu cầu tìm số lượng order của mỗi loại status(Close, complete, pending.....)\n",
    "  + Sử dụng hệ thống Spark, dữ liệu trong hdfs được chia thành 5 phần do 5 node trong cluster quản lí. Mỗi node quản lí 10k record.\n",
    "  + Để giải quyết tìm số lượng order của các status, ta thực hiện quy trình như trong ảnh: Load to Memory --> Map --> reduceByKey --> Collect\n",
    "  + Ở đây ta nhìn vào **map**: Mặc dù dữ liệu chuyển đổi từ string sang dictionary tuy nhiên bản chất nó vẫn vậy và nằm trong 1 node\n",
    "  + Ở đây ta nhìn vào **ReduceByKey**: Để tổng hợp số lượng Order của mỗi status, bắt buộc phải đưa dữ liệu về một chỗ, ở đây cụ thể là một node để tính. Ví dụ như trên hình trên, ta đã di chuyển dữ liệu Close về lại node đầu tiên để tổng hợp và tính.\n",
    "  + Việc đưa dữ liệu di chuyển rồi tổng hợp về một node như vậy gọi là Shuffle\n",
    "- Chỉ có **reduceByKey** mới shuffle nên gọi nó là **Wide**, còn **map** bản chất dữ liệu vẫn nằm tại một node nên gọi là **narrow**\n",
    "- Vì việc di chuyển dữ liệu giữa các node như vậy tốn rất nhiều dung lượng bộ nhớ làm cho chương trình thực thi bị chậm lại, nên trong các phép biến đổi transformation, ta ưu tiên đưa các narrow transformation lên trên đầu và đưa các wide transformation thực hiện ở các bước cuối để tối ưu hóa hiệu năng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Các transformations phổ biến"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **map(func)**: Áp dụng func lên tưng phần tử\n",
    "- **filter(func)**: Giữ lại các phần tử thỏa mãn func\n",
    "- **flatMap(func)**: Áp dụng func rồi trả về từng phần tử của output\n",
    "- **reduceByKey(func)**: Gom nhóm và áp dụng func theo từng khóa.\n",
    "- **groupByKey()**: Gom nhóm dữ liệu theo khóa.\n",
    "- **join(otherRDD)**: Ghép 2 RDD dựa trên khóa chung.\n",
    "- **distinct()**: Loại bỏ phần tử trùng lặp.\n",
    "- **sample(withReplacement, fraction)**: Lấy mẫu từ dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![famous transfomation](image_1/transfomation.png)\n",
    "\n",
    "\n",
    "<p style = 'color: green;'>Đặc điểm chung của các hàm trên:</p>\n",
    "\n",
    "- Đều sử dụng kèm theo một **function** bên trong, ngoại trừ *distinct*\n",
    "- Khi sử dụng những transformation này, ta quan tâm đến số lượng **input** và **output**\n",
    "\n",
    "<p style = 'color: green;'>Đếm dòng:</p>\n",
    "\n",
    "![famous transformation](image_1/transfomation_detail.png)\n",
    "\n",
    "- Map(func): Input là 1000 dòng thì Output là 1000 dòng. Khi làm bài cần số lượng output bằng số lượng input,\n",
    "ta liên tưởng đến hàm Map\n",
    "- Reduce(func): Chỉ trả về đúng 1 dòng thỏa điều hiện hàm.\n",
    "- ReduceByKey(func): Số lượng Output bằng số lượng KEY\n",
    "- Filter(func): Với spark, nên ưu tiên sử dụng transfomation filter này dùng trên cùng. Hàm lọc ra các giá trị thỏa mãn điều kiện. Số lượng OUTPUT < INPUT\n",
    "- SortBy(func): Sắp xếp giá trị, có thể dùng để tìm các giá trị lớn nhất, nhỏ nhất. Số lượng OUTPUT = INPUT\n",
    "- Distinct(): Cho ra các giá trị duy nhất, số lượng OUTPUT < INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Các Action phổ biến"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **collect()** : Trả về tất cả dữ liệu về drive (chỉ dùng cho dữ liệu nhỏ)\n",
    "- **count()**: Đếm số lượng phần tử\n",
    "- **take(n)**: Lấy n phàn tử đầu\n",
    "- **saveAsTextFile(path)**: Lưu kết quả vào thử mục theo dạng file văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài tập thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài 1**: Tìm 10 từ xuất hiện nhiều nhất trong một tập tin văn bản lớn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/06 11:10:59 WARN Utils: Your hostname, ubunchuu-Test resolves to a loopback address: 127.0.1.1; using 10.131.6.208 instead (on interface wlo1)\n",
      "24/11/06 11:10:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/06 11:11:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/06 11:11:12 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"material_1/vanban.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dem word count trong van ban\n",
    "word_count = rdd.flatMap(lambda x: x.split()) \\\n",
    "                .map(lambda word : (word,1)) \\\n",
    "                .reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Với', 1),\n",
       " ('nhiều', 2),\n",
       " ('ra', 5),\n",
       " ('trong', 4),\n",
       " ('gia', 1),\n",
       " ('đình', 1),\n",
       " ('nhập', 6),\n",
       " ('Florida', 2),\n",
       " ('đe', 1),\n",
       " ('dọa', 1),\n",
       " ('xuất', 6),\n",
       " ('loạt\"', 1),\n",
       " ('không', 1),\n",
       " ('lo', 2),\n",
       " ('bằng', 1),\n",
       " ('đề', 3),\n",
       " ('kinh', 1),\n",
       " ('Bước', 1),\n",
       " ('khỏi', 2),\n",
       " ('phòng', 1),\n",
       " ('bỏ', 1),\n",
       " ('Hialeah,', 1),\n",
       " ('thị', 1),\n",
       " ('với', 5),\n",
       " ('Florida,', 1),\n",
       " ('24', 1),\n",
       " ('tiết', 1),\n",
       " ('lộ', 1),\n",
       " ('đã', 3),\n",
       " ('cựu', 1),\n",
       " ('tổng', 3),\n",
       " ('thống', 2),\n",
       " ('thứ', 1),\n",
       " ('Mỹ,', 2),\n",
       " ('Colorado', 1),\n",
       " ('Nam', 1),\n",
       " ('Mỹ.', 1),\n",
       " ('được', 1),\n",
       " ('đánh', 1),\n",
       " ('một', 1),\n",
       " ('những', 2),\n",
       " ('chủ', 2),\n",
       " ('chốt', 1),\n",
       " ('năm', 2),\n",
       " ('nay.', 1),\n",
       " ('Trump', 3),\n",
       " ('lần', 1),\n",
       " ('nếu', 2),\n",
       " ('phát', 1),\n",
       " ('trục', 5),\n",
       " ('lớn', 1),\n",
       " ('nhất', 1),\n",
       " ('lịch', 1),\n",
       " ('Mỹ\",', 1),\n",
       " ('thậm', 1),\n",
       " ('định', 1),\n",
       " ('trao', 1),\n",
       " ('quốc', 1),\n",
       " ('Mỹ', 2),\n",
       " ('trên', 1),\n",
       " ('lãnh', 1),\n",
       " ('thổ', 1),\n",
       " ('visa', 1),\n",
       " ('du', 1),\n",
       " ('chuyển', 1),\n",
       " ('trước', 1),\n",
       " ('đang', 1),\n",
       " ('việc', 1),\n",
       " ('Miami,', 1),\n",
       " ('thông', 1),\n",
       " ('mà', 1),\n",
       " ('đưa', 1),\n",
       " ('bao', 2),\n",
       " ('ngại,', 1),\n",
       " ('kể', 1),\n",
       " ('khi', 2),\n",
       " ('Dân', 1),\n",
       " ('tục', 1),\n",
       " ('báo', 1),\n",
       " ('rằng', 1),\n",
       " ('quay', 1),\n",
       " ('Nhà', 1),\n",
       " ('mở', 1),\n",
       " ('chiến', 1),\n",
       " ('loạt', 1),\n",
       " ('mô', 1),\n",
       " ('có.', 1),\n",
       " ('\"Bố', 1),\n",
       " ('tôi', 1),\n",
       " ('Barack', 1),\n",
       " ('Obama', 1),\n",
       " ('Chuyện', 1),\n",
       " ('phái.', 1),\n",
       " ('xảy', 1),\n",
       " ('dưới', 1),\n",
       " ('dù', 1),\n",
       " ('Ngày', 1),\n",
       " ('5/11.', 1),\n",
       " ('cử', 3),\n",
       " ('tri', 1),\n",
       " ('sinh', 3),\n",
       " ('cư', 6),\n",
       " ('ở', 2),\n",
       " ('và', 3),\n",
       " ('bầu', 4),\n",
       " ('cho', 3),\n",
       " ('ông', 5),\n",
       " ('Trump,', 1),\n",
       " ('lời', 1),\n",
       " ('về', 2),\n",
       " ('\"trục', 1),\n",
       " ('hàng', 2),\n",
       " ('đáng', 1),\n",
       " ('vấn', 2),\n",
       " ('tế.', 1),\n",
       " ('phiếu', 1),\n",
       " ('tại', 4),\n",
       " ('trấn', 1),\n",
       " ('dân', 1),\n",
       " ('số', 1),\n",
       " ('hơn', 1),\n",
       " ('220.000', 1),\n",
       " ('người', 7),\n",
       " ('Alexander,', 2),\n",
       " ('tuổi,', 1),\n",
       " ('anh', 3),\n",
       " ('Donald', 1),\n",
       " ('Trump.', 1),\n",
       " ('Anh', 1),\n",
       " ('là', 5),\n",
       " ('thế', 1),\n",
       " ('hệ', 1),\n",
       " ('hai', 1),\n",
       " ('bố', 2),\n",
       " ('mẹ', 1),\n",
       " ('đều', 1),\n",
       " ('đến', 2),\n",
       " ('từ', 1),\n",
       " ('Chính', 1),\n",
       " ('sách', 1),\n",
       " ('giá', 1),\n",
       " ('then', 1),\n",
       " ('mùa', 1),\n",
       " ('Ông', 1),\n",
       " ('tuyên', 1),\n",
       " ('đắc', 1),\n",
       " ('cử,', 1),\n",
       " ('sẽ', 2),\n",
       " ('động', 1),\n",
       " ('\"chiến', 1),\n",
       " ('dịch', 2),\n",
       " ('sử', 1),\n",
       " ('chí', 1),\n",
       " ('chấm', 1),\n",
       " ('dứt', 1),\n",
       " ('quyền', 1),\n",
       " ('mặc', 1),\n",
       " ('tịch', 1),\n",
       " ('hủy', 1),\n",
       " ('học', 1),\n",
       " ('sinh.', 1),\n",
       " ('Nhưng', 1),\n",
       " ('vừa', 1),\n",
       " ('vài', 1),\n",
       " ('làm', 3),\n",
       " ('sân', 1),\n",
       " ('bay', 1),\n",
       " ('điệp', 1),\n",
       " ('chưa', 3),\n",
       " ('giờ', 2),\n",
       " ('cả', 1),\n",
       " ('đảng', 2),\n",
       " ('liên', 1),\n",
       " ('cảnh', 1),\n",
       " ('lại', 1),\n",
       " ('Trắng,', 1),\n",
       " ('quy', 1),\n",
       " ('từng', 1),\n",
       " ('bị', 1),\n",
       " ('thống.', 1),\n",
       " ('Nó', 1),\n",
       " ('mọi', 1),\n",
       " ('chính', 1),\n",
       " ('quyền,', 1),\n",
       " ('thắng', 1),\n",
       " ('ai\",', 1),\n",
       " ('nói', 1),\n",
       " ('VnExpress', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('người', 7),\n",
       " ('nhập', 6),\n",
       " ('xuất', 6),\n",
       " ('cư', 6),\n",
       " ('ra', 5),\n",
       " ('với', 5),\n",
       " ('trục', 5),\n",
       " ('ông', 5),\n",
       " ('là', 5),\n",
       " ('trong', 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sap xep giam dan va loc ra 10 gia tri dau tien\n",
    "top_10_word = word_count.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "top_10_word.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài 2:** Tính tổng doanh thu theo từng danh mục sản phẩm từ một RDD chứa dữ liệu bán hàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load to memory\n",
    "sales_rdd = sc.textFile(\"material_1/online_sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xem so luong dong\n",
    "sales_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10001,2024-01-01,Electronics,iPhone 14 Pro,2,999.99,1999.98,North America,Credit Card',\n",
       " '10002,2024-01-02,Home Appliances,Dyson V11 Vacuum,1,499.99,499.99,Europe,PayPal',\n",
       " \"10003,2024-01-03,Clothing,Levi's 501 Jeans,3,69.99,209.97,Asia,Debit Card\",\n",
       " '10004,2024-01-04,Books,The Da Vinci Code,4,15.99,63.96,North America,Credit Card',\n",
       " '10005,2024-01-05,Beauty Products,Neutrogena Skincare Set,1,89.99,89.99,Europe,PayPal',\n",
       " '10006,2024-01-06,Sports,Wilson Evolution Basketball,5,29.99,149.95,Asia,Credit Card',\n",
       " '10007,2024-01-07,Electronics,MacBook Pro 16-inch,1,2499.99,2499.99,North America,Credit Card',\n",
       " '10008,2024-01-08,Home Appliances,Blueair Classic 480i,2,599.99,1199.98,Europe,PayPal',\n",
       " '10009,2024-01-09,Clothing,Nike Air Force 1,6,89.99,539.94,Asia,Debit Card',\n",
       " '10010,2024-01-10,Books,Dune by Frank Herbert,2,25.99,51.98,North America,Credit Card']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xem 10 phan tu dau tien\n",
    "sales_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lấy ra category và total_price\n",
    "\n",
    "# Định nghia ham xu li tung line de lay ra category va total_price\n",
    "def safe_parse(line):\n",
    "    parts = line.split(\",\")\n",
    "    # Kiểm tra xem có đủ phần tử\n",
    "    if len(parts) > 6:\n",
    "        try:\n",
    "            # Lấy category (cột thứ 3) và giá trị doanh thu (cột thứ 7)\n",
    "            category = parts[2]\n",
    "            price = float(parts[6])  # Chuyển đổi thành float\n",
    "            return (category, price)\n",
    "        except ValueError:\n",
    "            # Bỏ qua dòng nếu không thể chuyển đổi sang float\n",
    "            print(f\"Skipping line due to ValueError: {line}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Bỏ qua dòng nếu không đủ phần tử\n",
    "        print(f\"Skipping line due to insufficient data: {line}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áp dụng hàm safe_parse và loại bỏ các dòng None\n",
    "\n",
    "type_map_sales_rdd = sales_rdd.map(safe_parse).filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Electronics', 1999.98),\n",
       " ('Home Appliances', 499.99),\n",
       " ('Clothing', 209.97),\n",
       " ('Books', 63.96),\n",
       " ('Beauty Products', 89.99),\n",
       " ('Sports', 149.95),\n",
       " ('Electronics', 2499.99),\n",
       " ('Home Appliances', 1199.98),\n",
       " ('Clothing', 539.94),\n",
       " ('Books', 51.98)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take 10 dong\n",
    "type_map_sales_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tinh tong doanh thu theo tung category\n",
    "\n",
    "revenue_rdd = type_map_sales_rdd.reduceByKey(lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line due to ValueError: 10016,2024-01-16,Books,\"Salt, Fat, Acid, Heat by Samin Nosrat\",3,35.99,107.97,North America,Credit Card\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Electronics', 34982.40999999999),\n",
       " ('Books', 1753.9600000000005),\n",
       " ('Home Appliances', 18646.159999999996),\n",
       " ('Clothing', 8128.9299999999985),\n",
       " ('Beauty Products', 2621.9),\n",
       " ('Sports', 14326.519999999999)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revenue_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài 3:** Ghép hai RDD dựa trên một khóa chung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử rdd1 và rdd2 chứa dữ liệu với ID chung\n",
    "rdd1 = sc.parallelize([(1, \"Alice\"), (2, \"Bob\"), (3, \"Carol\")])\n",
    "rdd2 = sc.parallelize([(1, 25), (2, 30), (4, 40)])\n",
    "\n",
    "# Ghép hai RDD dựa trên ID\n",
    "joined_rdd = rdd1.join(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, ('Alice', 25)), (2, ('Bob', 30))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai rdd trên chung khóa 1 và 2 nên dùng hai khóa đó ghép lại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
